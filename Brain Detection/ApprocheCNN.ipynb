{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmer les chemins des fichiers\n",
    "base_path = os.path.join(os.getcwd(), \"Brain-Tumor-Classification\")\n",
    "for dirname, _, filenames in os.walk(base_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les classes\n",
    "classes = os.listdir(os.path.join(base_path, \"Training\"))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # images \n",
    "y = [] # classes\n",
    "image_size = 150 # taille des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Boucle sur les dossiers Training et Testing\n",
    "for dataset_type in [\"Training\", \"Testing\"]:\n",
    "    for class_name in classes: # Boucle sur les classes\n",
    "        folder_path = os.path.join(base_path, dataset_type, class_name) # Chemin du dossier de la classe actuelle\n",
    "\n",
    "        # Boucle sur les fichiers du dossier actuel\n",
    "        for image_file in tqdm(os.listdir(folder_path)):\n",
    "            img_path = os.path.join(folder_path, image_file) # Chemin de l'image actuelle\n",
    "            try:\n",
    "                img = Image.open(img_path) # Ouvrir l'image\n",
    "                img = img.resize((image_size, image_size)) # Redimensionner l'image\n",
    "                img_array = np.array(img) # Convertir l'image en tableau numpy\n",
    "                if len(img_array.shape) != 3 or img_array.shape[2] != 3: # Vérifier que l'image est en couleur (3 canaux)\n",
    "                    print(f\"Image sans les 3 canaux pour {img_path}\")\n",
    "                    continue\n",
    "                X.append(img_array) # Ajouter l'image au tableau X\n",
    "                y.append(class_name) # Ajouter la classe au tableau y\n",
    "            except Exception as e:\n",
    "                print(f\"Impossible d'ouvrir l'image {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) # convertir la liste des images en tableau\n",
    "y = np.array(y) # convertir la liste des classes en tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nombre d'images chargées: {len(X)}\") \n",
    "print(f\"Nombre de label chargées: {len(y)}\")\n",
    "print(X.shape, y.shape) # Afficher la taille d'échantillon de X et y, ainsi que la taille d'une image et ses canaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0 # index pour les images\n",
    "figure, ax = plt.subplots(1,4,figsize=(20,20)) # 1 ligne, 4 colonnes\n",
    "figure.text(s=\"Echantillon d'images pour chaque classe\", size=20,fontweight='bold',y=0.62,x=0.5,ha='center',va='center')\n",
    "for i in classes:\n",
    "    j=0 # index pour les classes\n",
    "    while True :\n",
    "        if y[j]==i: # si la classe y[j] est égale à i\n",
    "            ax[k].imshow(X[j]) # afficher l'image correspondante à la X[j]\n",
    "            ax[k].set_title(y[j]) # afficher la classe de l'image en titre\n",
    "            ax[k].axis('off') # ne pas afficher les axes\n",
    "            k+=1\n",
    "            break\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y, random_state=42) # 80% pour le training et 20% pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = [] # liste pour les classes du training\n",
    "for i in y_train: \n",
    "    y_train_new.append(classes.index(i)) # remplacer les noms des classes par leurs indices\n",
    "y_train = y_train_new # mettre à jour les classes du training\n",
    "y_train = tf.keras.utils.to_categorical(y_train) # convertir les classes en one-hot encoding\n",
    "\n",
    "y_test_new = [] # liste pour les classes du test\n",
    "for i in y_test: \n",
    "    y_test_new.append(classes.index(i)) # remplacer les noms des classes par leurs indices\n",
    "y_test = y_test_new # mettre à jour les classes du test\n",
    "y_test = tf.keras.utils.to_categorical(y_test) # convertir les classes en one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator( # faire de la data augmentation\n",
    "    rotation_range=30, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "\n",
    "img_datagen.fit(X_train) # Fit la data augmentation\n",
    "img_datagen.fit(X_test) # fit la data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle\n",
    "model = Sequential() # modèle séquentiel\n",
    "\n",
    "# Ajouter les couches de convolution, activation, normalisation et pooling\n",
    "model.add(Conv2D(64, (3, 3), padding='same',input_shape=(image_size,image_size,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35)) #64 --> 42\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Ajouter les couches de Flatten, Dropout, Dense, Activation et BatchNormalization\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4)) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle\n",
    "history = model.fit(X_train,y_train,validation_split=0.1, epochs=10, verbose=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modèle\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modèle\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tester le modèle sur le training set\n",
    "predictions_tr = model.predict(X_train)\n",
    "predictions_tr = [np.argmax(x) for x in predictions_tr]\n",
    "\n",
    "accuracy_tr = accuracy_score(np.argmax(y_train, axis=1), predictions_tr)\n",
    "print('Training accuracy = %.4f' % accuracy_tr)\n",
    "\n",
    "f1_tr = f1_score(np.argmax(y_train, axis=1), predictions_tr, average='weighted')\n",
    "print('Training F1 score = %.4f' % f1_tr)\n",
    "\n",
    "confusion_mtx_tr = confusion_matrix(np.argmax(y_train, axis=1), predictions_tr)\n",
    "\n",
    "# Plot la matrice de confusion pour le training set\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx_tr, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Classes prédites')\n",
    "plt.ylabel('Classes réelles')\n",
    "plt.title('Matrice de confusion - Training Set')\n",
    "plt.show()\n",
    "\n",
    "# Tester le modèle sur le testing set\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_test = [np.argmax(x) for x in predictions_test]\n",
    "\n",
    "accuracy_test = accuracy_score(np.argmax(y_test, axis=1), predictions_test)\n",
    "print('Testing Accuracy = %.4f' % accuracy_test)\n",
    "\n",
    "f1_test = f1_score(np.argmax(y_test, axis=1), predictions_test, average='weighted')\n",
    "print('Testing F1 score = %.4f' % f1_test)\n",
    "\n",
    "confusion_mtx_test = confusion_matrix(np.argmax(y_test, axis=1), predictions_test)\n",
    "\n",
    "# Plot la matrice de confusion pour le testing set\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx_test, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Classes prédites')\n",
    "plt.ylabel('Classes réelles')\n",
    "plt.title('Matrice de confusion - Testing Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "y_test_labels = [np.argmax(label) for label in y_test] # Récupérer les labels du testing set\n",
    "# Afficher le classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_labels, predictions_test, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
